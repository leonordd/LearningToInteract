# LearningToInteract
Final Repository of Dissertation

0fullbody_record.py --> BASE Version learning_to_interact/2input/fullbody/fullbody_video_recording82_1.py

BASE Version learning_to_interact/comunication/v7/keypoints_optimized6/keypoints_optimized6.pde

learning_to_interact/toy/0input_pred.py Ã© o anterior mediapipe_holistic.py

1combine_files.py --> BASE Version learning_to_interact/00_pipeline/3combinar_ficheiros_csv2.py

2model_training.py --> BASE Version learning_to_interact/3integration/classification/version23/version22_1to4.py

Para instalar as dependÃªncias de python:
```bash
pip3 install -r requirements.txt
```

Para instalar as dependÃªncias de processing manualmente

```plaintext
COMO INSTALAR:
1. Abrir Processing IDE
2. Ir a Sketch > Import Library > Add Library...
3. Procurar e instalar as seguintes bibliotecas:

BIBLIOTECAS NECESSÃRIAS:
------------------------
1. VIDEO EXPORT
   Nome: Video Export
   Autor: Abe Pazos (hamoid)
   DescriÃ§Ã£o: Para exportar vÃ­deos (com.hamoid.*)
   
   OU pesquisar por: "hamoid" na biblioteca

BIBLIOTECAS JÃ INCLUÃDAS (NÃƒO INSTALAR):
----------------------------------------
As seguintes sÃ£o built-in do Processing/Java:
- javax.swing.* (interface grÃ¡fica)
- java.io.* (input/output de ficheiros)
- java.net.* (networking)
- java.util.concurrent.* (threading)
- java.text.* (formataÃ§Ã£o de texto/datas)

VERIFICAÃ‡ÃƒO:
-----------
ApÃ³s instalaÃ§Ã£o, verifica se pode usar:
import com.hamoid.*;

NOTA:
-----
Se nÃ£o encontrar "Video Export", pode tentar:
1. Descarregar diretamente do GitHub: https://github.com/hamoid/video_export_processing
2. Colocar na pasta libraries do seu sketchbook do Processing
```







# Treino de Modelo de ClassificaÃ§Ã£o com PyTorch

**Problema de ClassificaÃ§Ã£o**
Este projeto consiste no treino de um modelo de multiclassificaÃ§Ã£o que utiliza PyTorch, a partir de um dataset de inputs extraÃ­do de um ficheiro `.csv`. 

> âš ï¸ **Nota:** Esta versÃ£o foi extraÃ­da do Google Colab (version2.ipyn) e **nÃ£o inclui** a integraÃ§Ã£o entre as partes do MÃ³dulo III. Inclui apenas o treino do modelo.

---

## ğŸ“Œ ReferÃªncias Utilizadas

1. [Build your first ML model in Python (YouTube)](https://www.youtube.com/watch?v=29ZQ3TDGgRQ) | [Google Colab](https://colab.research.google.com/drive/1KDqZvbLXXc75TchFzWmuT43Qq4488HgN)
2. [Train Test Split with Python Machine Learning (Scikit-Learn)](https://www.youtube.com/watch?v=SjOfbbfI2qY)
3. [How to Train a Machine Learning Model with Python](https://www.youtube.com/watch?v=T1nSZWAksNA)
4. [Machine Learning Tutorial Python - 7](https://www.youtube.com/watch?v=fwY9Qv96DJY)
5. [Pytorch Multiclass Classification with ROC and AUC](https://www.youtube.com/watch?v=EoqXQTT74vY) | [GitHub](https://github.com/jeffheaton/app_deep_learning)

---

## ğŸ“‚ Estrutura do cÃ³digo de treino

```plaintext
ğŸ“ data/
   â””â”€â”€ dataset19/
   |   â””â”€â”€ combinado19.csv      # Dataset combinado
ğŸ“ output/                      # ficheiros do modelo treinado

ExplicaÃ§Ã£o de ficheiros:
ğŸ“„ version20.py                  # Script de treino do modelo, correr este ficheiro 1Âº. Treina o modelo apenas uma vez com uma arquitetura especifica definida. Com normalizaÃ§Ã£o de dados
ğŸ“„ integrated_system12.py        # script de prediÃ§Ãµes em tempo real
ğŸ“„ README.md                     # Este ficheiro
```

---

## âš™ï¸ Tecnologias Usadas
- Python 3.8+
- PyTorch
- pandas / NumPy
- scikit-learn
- Matplotlib / seaborn

---

## ğŸ§  LÃ³gica do CÃ³digo

### 1. **Carregar de Dados**
   - LÃª os dados de `combinado.csv`
   - Remove colunas irrelevantes (`zp`, `zlh`, `zrh`, etc.)
   - Separar o `X` e o `y`. Define `X` como as features e `y` como a variÃ¡vel `Valor`

   - feature_columns: colunas no ficheiro combinado.csv sem o `MillisSinceEpoch`,`LocalMillisProcessing`,`Valor`,`zp`,`zlh`, `zrh`, `fm`, ou seja, sem as coordenadas z e a face mesh, apenas a pose e o hand recognition
   - output: `Valor` (valores de 0 a 20), como representado na imagem seguida
        - 0: Fundo Branco (Processing) | Mesh ausente (python)
        - 1: Forma redonda (Processing) | Mesh a fazer um movimento qualquer (Python)
        - 2 a 6: Forma redonda que aumenta e diminui (Processing) | Movimento especÃ­fico da mÃ£o (Python)
        ![Figura exemplificativa do output](data/example.png)

### 2. **Preparar os dados**
   - Converter os dados em tensores PyTorch
   - Separar os dados em treino (80%) e teste/validaÃ§Ã£o (20%)

### 3. **Modelo PyTorch**
   - ImplementaÃ§Ã£o do modelo `FlexibleModel` com arquitetura da rede "personalizÃ¡vel" - `Neural Network`
   - FunÃ§Ã£o de Optimizer: `SGD`
   - FunÃ§Ã£o de loss: `CrossEntropyLoss`

### 4. **Treino**
   - Treino do modelo por 200 epochs (Going from raw logits -> prediction probabilities -> prediction labels)
   - AvaliaÃ§Ã£o da performance no conjunto de teste

### 5. **AvaliaÃ§Ã£o**
   - MÃ©tricas de accuracy
   - Matriz de confusÃ£o normalizada
   - VisualizaÃ§Ã£o com `plot_predictions` e `plot_decision_boundary`

### 6. **Guardar Modelo**
   - Guarda o modelo no ficheiro `trained_model_1to6.pth` com a informaÃ§Ã£o: input size, output size, arquitetura, etc.)

---

## ğŸ Como Executar

### 1. Clonar o repositÃ³rio:

```bash
git clone https://github.com/ #(ainda sem repo)
cd version20
```

### 2. Instalar as dependÃªncias:

```bash
pip install torch pandas numpy scikit-learn matplotlib seaborn

#ou (dependendo da versÃ£o de python)
pip3 install torch pandas numpy scikit-learn matplotlib seaborn
```

### 3. Corre o script principal

```bash
python version20.py

#ou (dependendo da versÃ£o de python)
python3 version20.py
```

---

## ğŸ’¾ Guardar e Carregar Modelo

```python
# Guardar
torch.save(model_info, 'data/trained_model_1to6.pth')

# Carregar
checkpoint = torch.load('data/trained_model_1to6.pth', map_location='cpu', weights_only=True)
```

---

## ğŸ§ª Print de valores

No final do cÃ³digo, existem partes que verificam os dados:
- NÃºmero de classes
- Arquitetura final do modelo
- DimensÃµes dos logits
- etc.

---