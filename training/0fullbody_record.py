# Version learning_to_interact/2input/fullbody/fullbody_video_recording82_1.py
# Sistema de Captura e An√°lise de Pose Corporal com MediaPipe - VERS√ÉO CORRIGIDA
# Corrige o problema de sincroniza√ß√£o entre tempo real e dura√ß√£o do v√≠deo
# adiciona o v√≠deo 

"""
Sistema de Captura e An√°lise de Pose Corporal com MediaPipe
Vers√£o com Sincroniza√ß√£o Temporal Precisa e Leitor de CSV

Autor: Sistema de Captura de Pose
Data: 2025
Funcionalidades:
- Captura de landmarks (pose, m√£os, rosto) com MediaPipe
- Sincroniza√ß√£o temporal de alta precis√£o
- Integra√ß√£o com v√≠deo de refer√™ncia
- Leitura e apresenta√ß√£o de dados CSV em tempo real
- Detec√ß√£o autom√°tica de drift temporal
- Grava√ß√£o sincronizada de v√≠deo e dados CSV
"""

import cv2
import mediapipe as mp
import csv
import os
import time
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from pathlib import Path


# ===========================================================================================
# CONFIGURA√á√ïES GLOBAIS
# ===========================================================================================

class Config:
    """Configura√ß√µes centralizadas do sistema."""
    
    # Tempo e Performance
    MAX_RECORDING_TIME_MS = 300000  # 5 minutos
    DRIFT_CHECK_INTERVAL = 5.0      # Verificar drift a cada 5 segundos
    DRIFT_THRESHOLD = 10            # Frames de diferen√ßa para considerar drift
    
    # C√¢mara
    CAMERA_WIDTH = 640
    CAMERA_HEIGHT = 480
    CAMERA_FPS = 60
    
    # MediaPipe
    MIN_DETECTION_CONFIDENCE = 0.5
    MIN_TRACKING_CONFIDENCE = 0.5
    MODEL_COMPLEXITY = 0  # 0=r√°pido, 2=preciso
    
    # Landmarks
    NUM_POSE_LANDMARKS = 33
    NUM_HAND_LANDMARKS = 21
    NUM_FACE_LANDMARKS = 468
    DEFAULT_LANDMARK_VALUE = 500.0
    
    # Visualiza√ß√£o
    SQUARE_SIZE = 3
    FACE_SQUARE_SIZE = 1
    SQUARE_COLOR = (255, 255, 255)  # Branco (BGR)
    
    # Debug
    DEBUG_FRAME_INTERVAL = 60  # Debug a cada 60 frames (~2s)


# ===========================================================================================
# UTILIT√ÅRIOS DE TEMPO E SINCRONIZA√á√ÉO
# ===========================================================================================

class TimeSync:
    """Utilit√°rios para sincroniza√ß√£o temporal precisa."""
    
    def __init__(self):
        self.start_timestamp = time.time()
        self.start_perf_counter = time.perf_counter()
        self.last_drift_check = 0
        self.drift_corrections = 0
    
    def get_elapsed_seconds(self) -> float:
        """Retorna tempo decorrido em segundos com m√°xima precis√£o."""
        return time.perf_counter() - self.start_perf_counter
    
    def get_current_timestamp_ms(self) -> int:
        """Retorna timestamp absoluto em milissegundos."""
        elapsed = self.get_elapsed_seconds()
        return int((self.start_timestamp + elapsed) * 1000)
    
    def check_drift(self, frame_count: int) -> bool:
        """
        Verifica e reporta drift temporal.
        
        Args:
            frame_count: N√∫mero atual de frames
            
        Returns:
            True se drift foi detectado
        """
        elapsed = self.get_elapsed_seconds()
        
        if elapsed - self.last_drift_check >= Config.DRIFT_CHECK_INTERVAL:
            expected_frames = elapsed * 30  # Assumindo 30 FPS
            frame_drift = abs(frame_count - expected_frames)
            
            if frame_drift > Config.DRIFT_THRESHOLD:
                self.drift_corrections += 1
                print(f"[SYNC] ‚ö†Ô∏è  Drift detectado: {frame_drift:.1f} frames aos {elapsed:.1f}s")
                self.last_drift_check = elapsed
                return True
            
            self.last_drift_check = elapsed
        
        return False
    
    def get_stats(self, frame_count: int) -> Dict[str, float]:
        """Retorna estat√≠sticas de sincroniza√ß√£o."""
        elapsed = self.get_elapsed_seconds()
        fps = frame_count / elapsed if elapsed > 0 else 0
        
        return {
            'elapsed_seconds': elapsed,
            'fps': fps,
            'drift_corrections': self.drift_corrections,
            'start_timestamp': self.start_timestamp
        }


# ===========================================================================================
# LEITOR DE DADOS CSV
# ===========================================================================================

class CSVDataReader:
    """Leitor inteligente de dados CSV com sincroniza√ß√£o temporal."""
    
    def __init__(self, path_csv: str):
        self.path_csv = path_csv
        self.data = None
        self.is_loaded = False
        self.time_column = None
        self.max_time = 0
        self.fps_detected = 30
        
        # Arrays para busca r√°pida
        self.time_array = None
        self.animation_array = None
        
        if path_csv and os.path.exists(path_csv):
            self._load_csv()
    
    def _load_csv(self):
        """Carrega e processa o ficheiro CSV."""
        try:
            self.data = pd.read_csv(self.path_csv)
            print(f"[CSV] ‚úÖ Carregado: {len(self.data)} linhas")
            print(f"[CSV] Colunas: {list(self.data.columns)}")
            
            if 'AnimacaoAtual' not in self.data.columns:
                print("[CSV] ‚ùå Coluna 'AnimacaoAtual' n√£o encontrada!")
                return
            
            self._detect_time_column()
            self._prepare_lookup_arrays()
            self._print_summary()
            
            self.is_loaded = True
            
        except Exception as e:
            print(f"[CSV] ‚ùå Erro ao carregar: {e}")
    
    def _detect_time_column(self):
        """Detecta coluna de tempo e calcula FPS."""
        time_columns = ['tempo', 'time', 'timestamp', 'segundos', 'Tempo', 'Time']
        
        for col in time_columns:
            if col in self.data.columns:
                self.time_column = col
                break
        
        if self.time_column is None:
            # Criar coluna baseada no √≠ndice
            estimated_duration = 300  # 5 minutos
            self.fps_detected = len(self.data) / estimated_duration
            self.fps_detected = np.clip(self.fps_detected, 10, 120)  # Limitar FPS
            
            self.data['tempo_calculado'] = self.data.index * (1/self.fps_detected)
            self.time_column = 'tempo_calculado'
        else:
            # Calcular FPS dos dados existentes
            if len(self.data) > 1:
                time_values = self.data[self.time_column].values
                time_diff = time_values[-1] - time_values[0]
                if time_diff > 0:
                    self.fps_detected = (len(self.data) - 1) / time_diff
        
        self.max_time = self.data[self.time_column].max()
    
    def _prepare_lookup_arrays(self):
        """Prepara arrays para busca bin√°ria r√°pida."""
        # Ordenar por tempo
        self.data = self.data.sort_values(by=self.time_column).reset_index(drop=True)
        
        # Criar arrays numpy para performance
        self.time_array = self.data[self.time_column].values
        self.animation_array = self.data['AnimacaoAtual'].values
    
    def _print_summary(self):
        """Imprime resumo das configura√ß√µes CSV."""
        print(f"[CSV] Configura√ß√£o:")
        print(f"[CSV]   - Coluna tempo: {self.time_column}")
        print(f"[CSV]   - FPS detectado: {self.fps_detected:.2f}")
        print(f"[CSV]   - Dura√ß√£o: {self.max_time:.2f}s")
        print(f"[CSV]   - Anima√ß√µes: {sorted(self.data['AnimacaoAtual'].unique())}")
    
    def get_animation_at_time(self, elapsed_seconds: float) -> Tuple[str, str, str]:
        """
        Obt√©m anima√ß√£o atual com informa√ß√µes de debug.
        
        Args:
            elapsed_seconds: Tempo decorrido
            
        Returns:
            Tuple (anima√ß√£o_original, anima√ß√£o_display, info_debug)
        """
        if not self.is_loaded:
            return "CSV n√£o carregado", "CSV n√£o carregado", "Erro"
        
        try:
            # Loop autom√°tico se necess√°rio
            effective_time = elapsed_seconds % self.max_time if self.max_time > 0 else elapsed_seconds
            
            # Busca bin√°ria
            idx = np.searchsorted(self.time_array, effective_time, side='right') - 1
            idx = np.clip(idx, 0, len(self.animation_array) - 1)
            
            animation_original = str(self.animation_array[idx])
            csv_time = self.time_array[idx]
            
            # Converter anima√ß√£o para display (+1)
            animation_display = self._convert_animation_for_display(animation_original)
            
            # Info de debug
            time_diff = abs(csv_time - effective_time)
            loop_count = int(elapsed_seconds // self.max_time) if self.max_time > 0 else 0
            
            debug_info = f"csv:{csv_time:.2f}|diff:{time_diff:.3f}|loop:{loop_count}|orig:{animation_original}"
            
            return animation_original, animation_display, debug_info
            
        except Exception as e:
            return f"Erro: {str(e)}", f"Erro: {str(e)}", "Erro"
    
    def _convert_animation_for_display(self, animation_value: str) -> str:
        """
        Converte valor da anima√ß√£o para display (+1).
        
        Args:
            animation_value: Valor original da anima√ß√£o
            
        Returns:
            Valor convertido para display
        """
        try:
            # Tentar converter para n√∫mero e adicionar 1
            if animation_value.isdigit():
                return str(int(animation_value) + 1)
            
            # Se for float
            try:
                float_val = float(animation_value)
                if float_val.is_integer():
                    return str(int(float_val) + 1)
                else:
                    return f"{float_val + 1:.1f}"
            except ValueError:
                pass
            
            # Se n√£o conseguir converter, retornar original
            return animation_value
            
        except Exception:
            return animation_value


# ===========================================================================================
# GESTOR DE V√çDEO DE REFER√äNCIA
# ===========================================================================================

class VideoManager:
    """Gestor de v√≠deo de refer√™ncia com sincroniza√ß√£o temporal."""
    
    def __init__(self, path_video: str):
        self.path_video = path_video
        self.cap = None
        self.current_frame = None
        self.fps = 30
        self.total_frames = 0
        self.current_frame_index = -1
        self.is_initialized = False
        
        if os.path.exists(path_video):
            self._initialize()
    
    def _initialize(self):
        """Inicializa o v√≠deo de refer√™ncia."""
        try:
            self.cap = cv2.VideoCapture(self.path_video)
            
            if not self.cap.isOpened():
                raise RuntimeError(f"N√£o foi poss√≠vel abrir: {self.path_video}")
            
            self.fps = self.cap.get(cv2.CAP_PROP_FPS)
            self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = self.total_frames / self.fps if self.fps > 0 else 0
            
            print(f"[VIDEO] ‚úÖ Carregado: {self.total_frames} frames, {self.fps:.2f} FPS, {duration:.2f}s")
            
            # Ler primeira frame
            ret, frame = self.cap.read()
            if ret:
                self.current_frame = frame
                self.current_frame_index = 0
            
            self.is_initialized = True
            
        except Exception as e:
            print(f"[VIDEO] ‚ùå Erro: {e}")
    
    def get_frame_at_time(self, elapsed_seconds: float) -> Optional[np.ndarray]:
        """
        Obt√©m frame do v√≠deo no tempo especificado.
        
        Args:
            elapsed_seconds: Tempo decorrido
            
        Returns:
            Frame do v√≠deo ou None
        """
        if not self.is_initialized or not self.cap:
            return None
        
        # Calcular frame alvo com loop
        target_frame = int(elapsed_seconds * self.fps) % self.total_frames
        
        # S√≥ avan√ßar se mudou de frame
        if target_frame != self.current_frame_index:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
            ret, frame = self.cap.read()
            
            if ret:
                self.current_frame = frame
                self.current_frame_index = target_frame
        
        return self.current_frame.copy() if self.current_frame is not None else None
    
    def release(self):
        """Liberta recursos."""
        if self.cap:
            self.cap.release()


# ===========================================================================================
# PROCESSADOR DE LANDMARKS
# ===========================================================================================

class LandmarkProcessor:
    """Processador de landmarks do MediaPipe."""
    
    @staticmethod
    def get_detection_status(results) -> Dict[str, int]:
        """Obt√©m status de detec√ß√£o de landmarks."""
        return {
            "face": 1 if results.face_landmarks else 0,
            "pose": 1 if results.pose_landmarks else 0,
            "left_hand": 1 if results.left_hand_landmarks else 0,
            "right_hand": 1 if results.right_hand_landmarks else 0
        }
    
    @staticmethod
    def extract_coordinates(landmarks, expected_count: int) -> List[float]:
        """Extrai coordenadas x,y,z de landmarks."""
        if landmarks:
            return [coord for lm in landmarks for coord in (lm.x, lm.y, lm.z)]
        else:
            return [Config.DEFAULT_LANDMARK_VALUE] * (expected_count * 3)
    
    @staticmethod
    def create_csv_row(results, timestamp_ms: int, status: Dict[str, int]) -> List:
        """Cria linha completa para CSV SEM AnimacaoAtual."""
        row = [timestamp_ms]
        row.extend([status["face"], status["pose"], status["right_hand"], status["left_hand"]])
        # REMOVIDO: row.append(animation_original)  # N√ÉO incluir AnimacaoAtual no CSV de sa√≠da
        
        # Extrair coordenadas
        pose_coords = LandmarkProcessor.extract_coordinates(
            results.pose_landmarks.landmark if results.pose_landmarks else None,
            Config.NUM_POSE_LANDMARKS
        )
        
        left_hand_coords = LandmarkProcessor.extract_coordinates(
            results.left_hand_landmarks.landmark if results.left_hand_landmarks else None,
            Config.NUM_HAND_LANDMARKS
        )
        
        right_hand_coords = LandmarkProcessor.extract_coordinates(
            results.right_hand_landmarks.landmark if results.right_hand_landmarks else None,
            Config.NUM_HAND_LANDMARKS
        )
        
        face_coords = LandmarkProcessor.extract_coordinates(
            results.face_landmarks.landmark if results.face_landmarks else None,
            Config.NUM_FACE_LANDMARKS
        )
        
        row.extend(pose_coords + left_hand_coords + right_hand_coords + face_coords)
        return row


# ===========================================================================================
# GESTOR DE FICHEIROS
# ===========================================================================================

class FileManager:
    """Gestor de ficheiros de sa√≠da."""
    
    @staticmethod
    def create_path_csv() -> Tuple[str, List[str]]:
        """Cria caminho e cabe√ßalho do CSV."""
        today = datetime.now().strftime('%Y_%m_%d')
        folder_path = os.path.join("../data", today)
        os.makedirs(folder_path, exist_ok=True)
        
        # Encontrar pr√≥xima vers√£o
        version = 1
        while os.path.exists(os.path.join(folder_path, f'v{version}.csv')):
            version += 1
        
        path_csv = os.path.join(folder_path, f'v{version}.csv')
        header = FileManager._create_csv_header()
        
        return path_csv, header
    
    @staticmethod
    def _create_csv_header() -> List[str]:
        """Cria cabe√ßalho completo do CSV SEM AnimacaoAtual."""
        header = ['MillisSinceEpoch', 'Face', 'Pose', 'RightHand', 'LeftHand']
        # REMOVIDO: 'AnimacaoAtual' do cabe√ßalho
        
        # Landmarks da pose
        for i in range(Config.NUM_POSE_LANDMARKS):
            header.extend([f'xp{i+1}', f'yp{i+1}', f'zp{i+1}'])
        
        # Landmarks das m√£os
        for i in range(Config.NUM_HAND_LANDMARKS):
            header.extend([f'xlh{i+1}', f'ylh{i+1}', f'zlh{i+1}'])
        
        for i in range(Config.NUM_HAND_LANDMARKS):
            header.extend([f'xrh{i+1}', f'yrh{i+1}', f'zrh{i+1}'])
        
        # Landmarks do rosto
        for i in range(Config.NUM_FACE_LANDMARKS):
            header.extend([f'xfm{i+1}', f'yfm{i+1}', f'zfm{i+1}'])
        
        return header
    
    @staticmethod
    def create_path_video() -> str:
        """Cria caminho do v√≠deo."""
        today = datetime.now().strftime('%Y_%m_%d')
        folder_path = os.path.join("../data", today)
        os.makedirs(folder_path, exist_ok=True)
        
        version = 1
        while os.path.exists(os.path.join(folder_path, f'v{version}.mp4')):
            version += 1
        
        return os.path.join(folder_path, f'v{version}.mp4')


# ===========================================================================================
# VISUALIZADOR
# ===========================================================================================

class Visualizer:
    """Gestor de visualiza√ß√£o e interface."""
    
    @staticmethod
    def draw_landmarks(image: np.ndarray, results):
        """Desenha landmarks como quadrados brancos."""
        h, w = image.shape[:2]
        
        # Landmarks do rosto (pequenos)
        if results.face_landmarks:
            for landmark in results.face_landmarks.landmark:
                x, y = int(landmark.x * w), int(landmark.y * h)
                cv2.rectangle(image, 
                            (x - Config.FACE_SQUARE_SIZE, y - Config.FACE_SQUARE_SIZE),
                            (x + Config.FACE_SQUARE_SIZE, y + Config.FACE_SQUARE_SIZE),
                            Config.SQUARE_COLOR, -1)
        
        # Landmarks da pose, m√£os (normais)
        for landmarks in [results.pose_landmarks, results.left_hand_landmarks, results.right_hand_landmarks]:
            if landmarks:
                for landmark in landmarks.landmark:
                    x, y = int(landmark.x * w), int(landmark.y * h)
                    cv2.rectangle(image,
                                (x - Config.SQUARE_SIZE, y - Config.SQUARE_SIZE),
                                (x + Config.SQUARE_SIZE, y + Config.SQUARE_SIZE),
                                Config.SQUARE_COLOR, -1)
    
    @staticmethod
    def add_info_overlay(image: np.ndarray, frame_count: int, elapsed_ms: float, 
                        animation_display: str, debug_info: str, has_video: bool):
        """Adiciona overlay com informa√ß√µes (mostra anima√ß√£o +1)."""
        elapsed_s = elapsed_ms / 1000
        max_s = Config.MAX_RECORDING_TIME_MS / 1000
        fps = frame_count / elapsed_s if elapsed_s > 0 else 0
        
        # Overlay principal
        overlay = image.copy()
        cv2.rectangle(overlay, (0, image.shape[0] - 30), (300, image.shape[0] ), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.8, image, 0.2, 0, image)
        
        # Anima√ß√£o atual (destaque) - usar valor +1 para display
        animation_name = animation_display.split(' (')[0] if animation_display else "N/A"
        cv2.putText(image, f"Anim: {animation_name}",
                   (15, image.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # Tempo
        cv2.putText(image, f"Tempo: {elapsed_s:.2f}s / {max_s:.0f}s",
                   (100, image.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # Debug de sincroniza√ß√£o
        #cv2.putText(image, f"Sync: {debug_info}",
                   #(15, image.shape[0] - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
        
        # FPS
        #cv2.putText(image, f"FPS: {fps:.1f}",
                   #(15, image.shape[0] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 255, 150), 1)
        
        # Indicador de v√≠deo
        #if has_video:
            #cv2.putText(image, "REF", (image.shape[1] - 50, 25),
                       #cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
    
    @staticmethod
    def create_split_screen(camera_frame: np.ndarray, video_frame: Optional[np.ndarray]) -> np.ndarray:
        """Cria tela dividida c√¢mara + v√≠deo."""
        camera_h, camera_w = camera_frame.shape[:2]
        target_width = 1280
        half_width = target_width // 2
        
        # Redimensionar c√¢mara
        camera_scale = half_width / camera_w
        camera_new_h = int(camera_h * camera_scale)
        camera_resized = cv2.resize(camera_frame, (half_width, camera_new_h))
        
        # Preparar v√≠deo
        if video_frame is not None:
            video_h, video_w = video_frame.shape[:2]
            video_scale = half_width / video_w
            video_new_h = int(video_h * video_scale)
            video_resized = cv2.resize(video_frame, (half_width, video_new_h))
            final_h = max(camera_new_h, video_new_h)
        else:
            final_h = camera_new_h
            video_resized = np.zeros((final_h, half_width, 3), dtype=np.uint8)
            cv2.putText(video_resized, "Sem video", (half_width//4, final_h//2),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        # Ajustar alturas
        if camera_new_h < final_h:
            padding = (final_h - camera_new_h) // 2
            camera_padded = np.zeros((final_h, half_width, 3), dtype=np.uint8)
            camera_padded[padding:padding + camera_new_h, :] = camera_resized
        else:
            camera_padded = camera_resized
        
        if video_frame is not None and video_new_h < final_h:
            padding = (final_h - video_new_h) // 2
            video_padded = np.zeros((final_h, half_width, 3), dtype=np.uint8)
            video_padded[padding:padding + video_new_h, :] = video_resized
        else:
            video_padded = video_resized
        
        # Combinar
        combined = np.hstack([camera_padded, video_padded])
        cv2.line(combined, (half_width, 0), (half_width, final_h), (255, 255, 255), 2)
        
        return combined


# ===========================================================================================
# SISTEMA PRINCIPAL DE CAPTURA
# ===========================================================================================

class PoseCaptureSystem:
    """Sistema principal de captura com sincroniza√ß√£o temporal."""
    
    def __init__(self, path_video: Optional[str] = None, path_csv: Optional[str] = None, 
                 split_screen: bool = True):
        # Componentes principais
        self.time_sync = TimeSync()
        self.csv_reader = CSVDataReader(path_csv) if path_csv else None
        self.video_manager = VideoManager(path_video) if path_video else None
        self.split_screen = split_screen
        
        # MediaPipe
        self.mp_holistic = mp.solutions.holistic
        
        # C√¢mara
        self.cap = self._setup_camera()
        
        # Ficheiros de sa√≠da
        self.path_csv, self.csv_header = FileManager.create_path_csv()
        self.path_video = FileManager.create_path_video()
        
        # Dados
        self.frames = []
        self.csv_data = []
        
        self._print_initialization_summary()
    
    def _setup_camera(self) -> cv2.VideoCapture:
        """Configura webcam."""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, Config.CAMERA_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, Config.CAMERA_HEIGHT)
        cap.set(cv2.CAP_PROP_FPS, Config.CAMERA_FPS)
        
        if not cap.isOpened():
            raise RuntimeError("Erro: N√£o foi poss√≠vel aceder √† webcam!")
        
        return cap
    
    def _print_initialization_summary(self):
        """Imprime resumo da inicializa√ß√£o."""
        print("[INIT] üéØ Sistema de Captura Inicializado")
        print(f"[INIT] CSV: {self.path_csv}")
        print(f"[INIT] V√≠deo: {self.path_video}")
        
        if self.csv_reader and self.csv_reader.is_loaded:
            print("[INIT] ‚úÖ Dados CSV carregados")
        
        if self.video_manager and self.video_manager.is_initialized:
            print("[INIT] ‚úÖ V√≠deo de refer√™ncia carregado")
        
        if self.split_screen and self.video_manager:
            print("[INIT] üì∫ Modo: Tela dividida")
        else:
            print("[INIT] ü™ü Modo: Janelas separadas")
    
    def run(self):
        """Executa captura principal."""
        print(f"\n[CAPTURE] üé¨ Iniciando captura de {Config.MAX_RECORDING_TIME_MS/1000:.0f}s")
        print("[CAPTURE] Pressione 'q' para parar")
        
        self._setup_windows()
        
        frame_count = 0
        
        try:
            with self.mp_holistic.Holistic(
                min_detection_confidence=Config.MIN_DETECTION_CONFIDENCE,
                min_tracking_confidence=Config.MIN_TRACKING_CONFIDENCE,
                refine_face_landmarks=False,
                model_complexity=Config.MODEL_COMPLEXITY
            ) as holistic:
                
                while self.cap.isOpened():
                    success, image = self.cap.read()
                    if not success:
                        continue
                    
                    # Tempo atual
                    elapsed_s = self.time_sync.get_elapsed_seconds()
                    elapsed_ms = elapsed_s * 1000
                    timestamp_ms = self.time_sync.get_current_timestamp_ms()
                    frame_count += 1
                    
                    # Verificar tempo limite
                    if elapsed_ms >= Config.MAX_RECORDING_TIME_MS:
                        print("[CAPTURE] ‚è∞ Tempo m√°ximo atingido")
                        break
                    
                    # Verificar drift
                    self.time_sync.check_drift(frame_count)
                    
                    # Obter anima√ß√£o atual APENAS para display (n√£o para CSV)
                    animation_original, animation_display, debug_info = "N/A", "N/A", ""
                    if self.csv_reader and self.csv_reader.is_loaded:
                        animation_original, animation_display, debug_info = self.csv_reader.get_animation_at_time(elapsed_s)
                    
                    # Processar landmarks
                    image.flags.writeable = False
                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    results = holistic.process(image_rgb)
                    
                    # Recolher dados SEM incluir AnimacaoAtual
                    status = LandmarkProcessor.get_detection_status(results)
                    csv_row = LandmarkProcessor.create_csv_row(results, timestamp_ms, status)  # REMOVIDO animation_original
                    self.csv_data.append(csv_row)
                    
                    # Debug peri√≥dico (mostrar valor +1 apenas para display)
                    if frame_count % Config.DEBUG_FRAME_INTERVAL == 0:
                        fps = frame_count / elapsed_s if elapsed_s > 0 else 0
                        display_anim = animation_display.split(' (')[0] if animation_display else "N/A"
                        print(f"[DEBUG] Frame {frame_count}: "
                            f"F{status['face']}P{status['pose']}L{status['left_hand']}R{status['right_hand']} "
                            f"T={elapsed_s:.2f}s FPS={fps:.1f} Anim={display_anim}")
                    
                    # Visualiza√ß√£o (mostrar valor +1 apenas na interface)
                    image.flags.writeable = True
                    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
                    
                    Visualizer.draw_landmarks(image, results)
                    Visualizer.add_info_overlay(image, frame_count, elapsed_ms, animation_display, debug_info,
                                            self.video_manager is not None)
                    
                    self._display_frames(image, elapsed_s)
                    self.frames.append(image.copy())
                    
                    # Verificar teclas
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        print("[CAPTURE] üõë Parado pelo utilizador")
                        break
        
        finally:
            self._cleanup_and_save()
    
    def _setup_windows(self):
        """Configura janelas de visualiza√ß√£o."""
        if self.split_screen and self.video_manager:
            cv2.namedWindow('Captura - Camara + Video', cv2.WINDOW_NORMAL)
            cv2.resizeWindow('Captura - Camara + Video', 1280, 600)
        else:
            cv2.namedWindow('Captura de Pose', cv2.WINDOW_NORMAL)
            if self.video_manager:
                cv2.namedWindow('Video de Referencia', cv2.WINDOW_NORMAL)
                cv2.moveWindow('Video de Referencia', 700, 100)
    
    def _display_frames(self, camera_frame: np.ndarray, elapsed_s: float):
        """Exibe frames na interface."""
        if self.split_screen and self.video_manager:
            # Tela dividida
            video_frame = self.video_manager.get_frame_at_time(elapsed_s)
            combined = Visualizer.create_split_screen(camera_frame, video_frame)
            cv2.imshow('Captura - Camara + Video', combined)
        else:
            # Janelas separadas
            cv2.imshow('Captura de Pose', camera_frame)
            if self.video_manager:
                video_frame = self.video_manager.get_frame_at_time(elapsed_s)
                if video_frame is not None:
                    cv2.imshow('Video de Referencia', video_frame)
    
    def _cleanup_and_save(self):
        """Limpa recursos e guarda ficheiros."""
        # Fechar recursos
        self.cap.release()
        if self.video_manager:
            self.video_manager.release()
        cv2.destroyAllWindows()
        
        # Obter estat√≠sticas
        stats = self.time_sync.get_stats(len(self.frames))
        
        print(f"\n[SAVE] üíæ A guardar {len(self.frames)} frames...")
        
        # Guardar CSV
        self._save_csv(stats)
        
        # Guardar v√≠deo
        self._save_video(stats)
        
        # Relat√≥rio final
        self._print_final_report(stats)
    
    def _save_csv(self, stats: Dict[str, float]):
        """Guarda ficheiro CSV apenas com cabe√ßalho e dados."""
        with open(self.path_csv, 'w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(self.csv_header)
            writer.writerows(self.csv_data)
    
    def _save_video(self, stats: Dict[str, float]):
        """Guarda v√≠deo com FPS otimizado."""
        # Calcular FPS ideal
        target_fps = min(max(stats["fps"], 15), 60)
        if abs(target_fps - 30) > 15:
            target_fps = 30
        
        # Gravar v√≠deo
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(self.path_video, fourcc, target_fps,
                                (Config.CAMERA_WIDTH, Config.CAMERA_HEIGHT))
        
        for frame in self.frames:
            writer.write(frame)
        writer.release()
    
    def _print_final_report(self, stats: Dict[str, float]):
        """Imprime relat√≥rio final."""
        video_duration = len(self.frames) / 30  # Assumindo 30 FPS
        time_accuracy = abs(stats["elapsed_seconds"] - video_duration)
        
        if time_accuracy < 0.1:
            quality = "EXCELENTE"
        elif time_accuracy < 0.5:
            quality = "BOA"
        else:
            quality = "ACEIT√ÅVEL"
        
        print("\n" + "="*70)
        print("[FINAL] üéØ CAPTURA CONCLU√çDA")
        print("="*70)
        print(f"[FINAL] ‚è±Ô∏è  Dura√ß√£o real: {stats['elapsed_seconds']:.3f}s")
        print(f"[FINAL] üìπ Frames capturadas: {len(self.frames)}")
        print(f"[FINAL] üé¨ FPS m√©dio: {stats['fps']:.2f}")
        print(f"[FINAL] üìê Precis√£o temporal: ¬±{time_accuracy:.3f}s ({quality})")
        print(f"[FINAL] üîß Corre√ß√µes drift: {stats['drift_corrections']}")
        print(f"[FINAL] üìä CSV: {self.path_csv}")
        print(f"[FINAL] üé• V√≠deo: {self.path_video}")
        
        if self.csv_reader and self.csv_reader.is_loaded:
            print(f"[FINAL] üîó Sincroniza√ß√£o CSV: ATIVA")
        
        if quality == "EXCELENTE":
            print("[FINAL] ‚úÖ Sincroniza√ß√£o temporal excelente!")
        elif time_accuracy > 1.0:
            print("[FINAL] ‚ö†Ô∏è  AVISO: Discrep√¢ncia temporal elevada!")
        
        print("="*70)


# ===========================================================================================
# FUN√á√ÉO PRINCIPAL
# ===========================================================================================

def main():
    """Fun√ß√£o principal do programa."""
    try:
        print("üéØ Sistema de Captura de Pose com Sincroniza√ß√£o Temporal")
        print("="*70)
        
        # Caminhos dos ficheiros
        #folder = "../data/dataset30"
        folder_video_and_csv = "../data/0base"
        video = "video1.mp4"
        csv = "dados_teclas1.csv"

        path_video = Path(__file__).resolve().parent / folder_video_and_csv / video
        path_csv = Path(__file__).resolve().parent / folder_video_and_csv / csv
        
        # Verificar ficheiros
        video_exists = os.path.exists(path_video)
        csv_exists = os.path.exists(path_csv)
        
        print(f"[MAIN] V√≠deo: {'‚úÖ' if video_exists else '‚ùå'} {path_video}")
        print(f"[MAIN] CSV: {'‚úÖ' if csv_exists else '‚ùå'} {path_csv}")
        
        # Validar CSV
        if not csv_exists:
            print("\n‚ö†Ô∏è  Ficheiro CSV n√£o encontrado!")
            print("Certifique-se que existe com coluna 'AnimacaoAtual'")
            
            if input("Continuar sem CSV? (s/N): ").strip().lower() != 's':
                return
            path_csv = None
        
        # Validar v√≠deo
        if not video_exists:
            print("‚ö†Ô∏è  V√≠deo de refer√™ncia n√£o encontrado!")
            path_video = None
        
        # Escolher modo de visualiza√ß√£o
        split_screen = True
        if path_video:
            print("\n[MAIN] Modo de visualiza√ß√£o:")
            print("1 - Tela dividida (recomendado)")
            print("2 - Janelas separadas")
            
            choice = input("Escolha (1-2, padr√£o=1): ").strip()
            split_screen = choice != "2"
        
        # Mostrar funcionalidades ativas
        print("\nüéØ Funcionalidades Ativas:")
        print("‚è±Ô∏è  - Sincroniza√ß√£o temporal de alta precis√£o")
        print("üîÑ - Detec√ß√£o autom√°tica de drift")
        print("üìä - Monitoriza√ß√£o FPS em tempo real")
        if path_csv:
            print("üìã - Integra√ß√£o com dados CSV")
        if path_video:
            print("üé¨ - V√≠deo de refer√™ncia sincronizado")
        
        # Inicializar e executar
        print("\n[MAIN] Iniciando em 3 segundos...")
        time.sleep(3)
        
        system = PoseCaptureSystem(path_video, path_csv, split_screen)
        system.run()
        
    except KeyboardInterrupt:
        print("\n[MAIN] üõë Interrompido pelo utilizador")
    except Exception as e:
        print(f"\n[ERROR] ‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("[MAIN] üîö Programa terminado")


if __name__ == "__main__":
    main()