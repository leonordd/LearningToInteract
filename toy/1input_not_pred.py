# 3realtime_prediction.py
# Sistema de PrediÃ§Ãµes em Tempo Real com MediaPipe
# Carrega modelo treinado e faz inferÃªncias em tempo real

"""
Sistema de PrediÃ§Ãµes em Tempo Real
VersÃ£o baseada no sistema de captura com prediÃ§Ãµes de IA

Autor: Sistema de PrediÃ§Ãµes
Data: 2025
Funcionalidades:
- Carregamento do modelo treinado
- Captura de landmarks em tempo real
- PrediÃ§Ãµes instantÃ¢neas
- VisualizaÃ§Ã£o da prediÃ§Ã£o atual
- Modo de debug com confianÃ§a
"""

import cv2
import mediapipe as mp
import torch
import torch.nn.functional as F
import numpy as np
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import json


# ===========================================================================================
# CONFIGURAÃ‡Ã•ES GLOBAIS
# ===========================================================================================

class PredictionConfig:
    """ConfiguraÃ§Ãµes centralizadas do sistema de prediÃ§Ã£o."""
    
    # CÃ¢mara
    CAMERA_WIDTH = 640
    CAMERA_HEIGHT = 480
    CAMERA_FPS = 60
    
    # MediaPipe
    MIN_DETECTION_CONFIDENCE = 0.5
    MIN_TRACKING_CONFIDENCE = 0.5
    MODEL_COMPLEXITY = 0  # 0=rÃ¡pido, 2=preciso
    
    # Landmarks
    NUM_POSE_LANDMARKS = 33
    NUM_HAND_LANDMARKS = 21
    NUM_FACE_LANDMARKS = 468
    DEFAULT_LANDMARK_VALUE = 0.0  # Valor para landmarks nÃ£o detectados
    
    # VisualizaÃ§Ã£o
    SQUARE_SIZE = 3
    FACE_SQUARE_SIZE = 1
    SQUARE_COLOR = (255, 255, 255)  # Branco (BGR)
    
    # PrediÃ§Ãµes
    CONFIDENCE_THRESHOLD = 0.3  # Limiar mÃ­nimo para mostrar prediÃ§Ã£o
    SMOOTHING_WINDOW = 5  # Janela para suavizaÃ§Ã£o de prediÃ§Ãµes
    PREDICTION_DISPLAY_TIME = 2000  # ms para mostrar prediÃ§Ã£o
    
    # Debug
    SHOW_DEBUG_INFO = True
    FPS_UPDATE_INTERVAL = 30  # Atualizar FPS a cada 30 frames


# ===========================================================================================
# MODELO DE REDE NEURAL (DEVE SER IDÃŠNTICO AO TREINO)
# ===========================================================================================

class WeightedFlexibleModel(torch.nn.Module):
    """Modelo de rede neural flexÃ­vel com pesos por classe."""
    
    def __init__(self, input_size, output_size, hidden_layers, class_weights=None):
        super().__init__()
        
        self.class_weights = class_weights
        layer_sizes = [input_size] + hidden_layers + [output_size]
        
        self.layers = torch.nn.ModuleList()
        for i in range(len(layer_sizes) - 1):
            self.layers.append(torch.nn.Linear(layer_sizes[i], layer_sizes[i + 1]))
            
        self.dropout = torch.nn.Dropout(0.2)
        self.activation = torch.nn.ReLU()
        
    def forward(self, x):
        for layer in self.layers[:-1]:
            x = layer(x)
            x = self.activation(x)
            x = self.dropout(x)
        
        # Ãšltima camada sem ativaÃ§Ã£o
        logits = self.layers[-1](x)
        return logits
    
    def predict_with_confidence(self, x):
        """PrediÃ§Ã£o com cÃ¡lculo de confianÃ§a."""
        self.eval()
        with torch.no_grad():
            logits = self.forward(x)
            probs = F.softmax(logits, dim=1)
            confidences, predictions = torch.max(probs, dim=1)
            
            return predictions, confidences, probs


# ===========================================================================================
# CARREGADOR DE MODELO
# ===========================================================================================

class ModelLoader:
    """Classe para carregar o modelo treinado e suas configuraÃ§Ãµes."""
    
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.model = None
        self.model_info = None
        self.feature_names = None
        self.device = self._get_device()
        
        self._load_model()
    
    def _get_device(self):
        """Determina o dispositivo disponÃ­vel."""
        if torch.cuda.is_available():
            return "cuda"
        elif torch.backends.mps.is_available():
            return "mps"
        else:
            return "cpu"
    
    def _load_model(self):
        """Carrega o modelo e suas informaÃ§Ãµes."""
        try:
            print(f"[MODEL] Carregando modelo de: {self.model_path}")
            
            # Carregar informaÃ§Ãµes do modelo
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.model_info = checkpoint
            
            # Extrair configuraÃ§Ãµes
            input_size = checkpoint['input_size']
            output_size = checkpoint['output_size']
            hidden_layers = checkpoint['hidden_layers']
            
            # Criar modelo
            self.model = WeightedFlexibleModel(
                input_size=input_size,
                output_size=output_size,
                hidden_layers=hidden_layers
            ).to(self.device)
            
            # Carregar pesos
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            # Extrair informaÃ§Ãµes de features
            if 'feature_info' in checkpoint:
                self.feature_names = checkpoint['feature_info'].get('feature_order', [])
            
            print(f"[MODEL] âœ… Modelo carregado com sucesso!")
            print(f"[MODEL] Device: {self.device}")
            print(f"[MODEL] Input size: {input_size}")
            print(f"[MODEL] Output size: {output_size}")
            print(f"[MODEL] Hidden layers: {hidden_layers}")
            print(f"[MODEL] Features: {len(self.feature_names) if self.feature_names else 'N/A'}")
            
            # Mostrar mÃ©tricas se disponÃ­veis
            if 'best_accuracy' in checkpoint:
                print(f"[MODEL] Accuracy treino: {checkpoint['best_accuracy']:.2f}%")
            
        except Exception as e:
            print(f"[MODEL] âŒ Erro ao carregar modelo: {e}")
            raise
    
    def get_model_info(self):
        """Retorna informaÃ§Ãµes do modelo."""
        return {
            'input_size': self.model_info['input_size'],
            'output_size': self.model_info['output_size'],
            'feature_names': self.feature_names,
            'device': self.device,
            'preprocessing': self.model_info.get('preprocessing_details', {}),
            'best_accuracy': self.model_info.get('best_accuracy', 'N/A')
        }


# ===========================================================================================
# PROCESSADOR DE LANDMARKS PARA PREDIÃ‡ÃƒO
# ===========================================================================================

class LandmarkPreprocessor:
    """Processa landmarks do MediaPipe para formato de prediÃ§Ã£o."""
    
    @staticmethod
    def extract_coordinates(landmarks, expected_count: int) -> List[float]:
        """Extrai coordenadas x,y,z de landmarks."""
        if landmarks:
            return [coord for lm in landmarks for coord in (lm.x, lm.y, lm.z)]
        else:
            return [PredictionConfig.DEFAULT_LANDMARK_VALUE] * (expected_count * 3)
    
    @staticmethod
    def create_feature_vector(results) -> np.ndarray:
        """Cria vetor de features a partir dos resultados do MediaPipe."""
        
        # Extrair coordenadas (mesma ordem que no treino)
        pose_coords = LandmarkPreprocessor.extract_coordinates(
            results.pose_landmarks.landmark if results.pose_landmarks else None,
            PredictionConfig.NUM_POSE_LANDMARKS
        )
        
        left_hand_coords = LandmarkPreprocessor.extract_coordinates(
            results.left_hand_landmarks.landmark if results.left_hand_landmarks else None,
            PredictionConfig.NUM_HAND_LANDMARKS
        )
        
        right_hand_coords = LandmarkPreprocessor.extract_coordinates(
            results.right_hand_landmarks.landmark if results.right_hand_landmarks else None,
            PredictionConfig.NUM_HAND_LANDMARKS
        )
        
        face_coords = LandmarkPreprocessor.extract_coordinates(
            results.face_landmarks.landmark if results.face_landmarks else None,
            PredictionConfig.NUM_FACE_LANDMARKS
        )
        
        # Combinar todas as coordenadas (mesma ordem que no treino)
        feature_vector = pose_coords + left_hand_coords + right_hand_coords + face_coords
        
        return np.array(feature_vector, dtype=np.float32)
    
    @staticmethod
    def get_detection_status(results) -> Dict[str, bool]:
        """ObtÃ©m status de detecÃ§Ã£o de landmarks."""
        return {
            "face": results.face_landmarks is not None,
            "pose": results.pose_landmarks is not None,
            "left_hand": results.left_hand_landmarks is not None,
            "right_hand": results.right_hand_landmarks is not None
        }


# ===========================================================================================
# SUAVIZAÃ‡ÃƒO DE PREDIÃ‡Ã•ES
# ===========================================================================================

class PredictionSmoother:
    """Classe para suavizar prediÃ§Ãµes ao longo do tempo."""
    
    def __init__(self, window_size: int = 5):
        self.window_size = window_size
        self.prediction_history = []
        self.confidence_history = []
    
    def add_prediction(self, prediction: int, confidence: float):
        """Adiciona nova prediÃ§Ã£o ao histÃ³rico."""
        self.prediction_history.append(prediction)
        self.confidence_history.append(confidence)
        
        # Manter apenas as Ãºltimas N prediÃ§Ãµes
        if len(self.prediction_history) > self.window_size:
            self.prediction_history.pop(0)
            self.confidence_history.pop(0)
    
    def get_smoothed_prediction(self) -> Tuple[int, float]:
        """Retorna prediÃ§Ã£o suavizada baseada no histÃ³rico."""
        if not self.prediction_history:
            return -1, 0.0
        
        # Usar moda para prediÃ§Ã£o (mais frequente)
        unique_predictions, counts = np.unique(self.prediction_history, return_counts=True)
        most_common_idx = np.argmax(counts)
        smoothed_prediction = unique_predictions[most_common_idx]
        
        # MÃ©dia das confianÃ§as para essa prediÃ§Ã£o
        matching_confidences = [conf for pred, conf in zip(self.prediction_history, self.confidence_history) 
                               if pred == smoothed_prediction]
        smoothed_confidence = np.mean(matching_confidences) if matching_confidences else 0.0
        
        return int(smoothed_prediction), float(smoothed_confidence)
    
    def get_stability_score(self) -> float:
        """Retorna score de estabilidade das prediÃ§Ãµes (0-1)."""
        if len(self.prediction_history) < 2:
            return 0.0
        
        # Calcular quantas prediÃ§Ãµes sÃ£o iguais Ã  mais recente
        recent_prediction = self.prediction_history[-1]
        matches = sum(1 for pred in self.prediction_history if pred == recent_prediction)
        
        return matches / len(self.prediction_history)


# ===========================================================================================
# VISUALIZADOR PARA PREDIÃ‡Ã•ES
# ===========================================================================================

class PredictionVisualizer:
    """Classe para visualizar prediÃ§Ãµes e informaÃ§Ãµes na tela."""
    
    @staticmethod
    def draw_landmarks(image: np.ndarray, results):
        """Desenha landmarks como quadrados brancos."""
        h, w = image.shape[:2]
        
        # Landmarks do rosto (pequenos)
        if results.face_landmarks:
            for landmark in results.face_landmarks.landmark:
                x, y = int(landmark.x * w), int(landmark.y * h)
                cv2.rectangle(image, 
                            (x - PredictionConfig.FACE_SQUARE_SIZE, y - PredictionConfig.FACE_SQUARE_SIZE),
                            (x + PredictionConfig.FACE_SQUARE_SIZE, y + PredictionConfig.FACE_SQUARE_SIZE),
                            PredictionConfig.SQUARE_COLOR, -1)
        
        # Landmarks da pose, mÃ£os (normais)
        for landmarks in [results.pose_landmarks, results.left_hand_landmarks, results.right_hand_landmarks]:
            if landmarks:
                for landmark in landmarks.landmark:
                    x, y = int(landmark.x * w), int(landmark.y * h)
                    cv2.rectangle(image,
                                (x - PredictionConfig.SQUARE_SIZE, y - PredictionConfig.SQUARE_SIZE),
                                (x + PredictionConfig.SQUARE_SIZE, y + PredictionConfig.SQUARE_SIZE),
                                PredictionConfig.SQUARE_COLOR, -1)
    
    @staticmethod
    def add_prediction_overlay(image: np.ndarray, prediction: int, confidence: float, 
                             smoothed_prediction: int, smoothed_confidence: float,
                             stability: float, fps: float, detection_status: Dict[str, bool]):
        """Adiciona overlay com informaÃ§Ãµes de prediÃ§Ã£o."""
        h, w = image.shape[:2]
        
        # Cor baseada na confianÃ§a
        if smoothed_confidence > 0.7:
            confidence_color = (0, 255, 0)  # Verde
        elif smoothed_confidence > 0.4:
            confidence_color = (0, 255, 255)  # Amarelo
        else:
            confidence_color = (0, 0, 255)  # Vermelho
        
        # Criar overlay escuro para melhor legibilidade
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (w, 120), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)
        
        # PrediÃ§Ã£o principal (grande)
        main_text = f"Animacao: {smoothed_prediction + 1}"  # +1 para display (1-4 em vez de 0-3)
        cv2.putText(image, main_text, (20, 40), cv2.FONT_HERSHEY_DUPLEX, 1.2, confidence_color, 2)
        
        # ConfianÃ§a
        conf_text = f"Confianca: {smoothed_confidence:.2f}"
        cv2.putText(image, conf_text, (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, confidence_color, 2)
        
        # Estabilidade
        stability_text = f"Estabilidade: {stability:.2f}"
        cv2.putText(image, stability_text, (20, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # Status de detecÃ§Ã£o (canto superior direito)
        status_x = w - 200
        cv2.putText(image, "Deteccao:", (status_x, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        status_symbols = []
        if detection_status["face"]: status_symbols.append("F")
        if detection_status["pose"]: status_symbols.append("P")
        if detection_status["left_hand"]: status_symbols.append("LH")
        if detection_status["right_hand"]: status_symbols.append("RH")
        
        status_text = " ".join(status_symbols) if status_symbols else "NENHUMA"
        status_color = (0, 255, 0) if len(status_symbols) >= 2 else (0, 255, 255) if status_symbols else (0, 0, 255)
        cv2.putText(image, status_text, (status_x, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)
        
        # FPS (canto inferior direito)
        fps_text = f"FPS: {fps:.1f}"
        cv2.putText(image, fps_text, (w - 100, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # Debug info (se ativado)
        if PredictionConfig.SHOW_DEBUG_INFO:
            debug_text = f"Raw: {prediction + 1} ({confidence:.2f})"  # +1 para display
            cv2.putText(image, debug_text, (20, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)


# ===========================================================================================
# SISTEMA PRINCIPAL DE PREDIÃ‡ÃƒO
# ===========================================================================================

class RealtimePredictionSystem:
    """Sistema principal de prediÃ§Ãµes em tempo real."""
    
    def __init__(self, model_path: str):
        print("ğŸ¯ Inicializando Sistema de PrediÃ§Ãµes em Tempo Real")
        print("=" * 60)
        
        # Carregar modelo
        self.model_loader = ModelLoader(model_path)
        self.model = self.model_loader.model
        self.device = self.model_loader.device
        
        # Componentes do sistema
        self.preprocessor = LandmarkPreprocessor()
        self.smoother = PredictionSmoother(window_size=PredictionConfig.SMOOTHING_WINDOW)
        self.visualizer = PredictionVisualizer()
        
        # MediaPipe
        self.mp_holistic = mp.solutions.holistic
        
        # CÃ¢mara
        self.cap = self._setup_camera()
        
        # EstatÃ­sticas
        self.frame_count = 0
        self.start_time = time.time()
        self.last_fps_update = 0
        self.current_fps = 0
        
        self._print_initialization_summary()
    
    def _setup_camera(self) -> cv2.VideoCapture:
        """Configura webcam."""
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, PredictionConfig.CAMERA_WIDTH)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, PredictionConfig.CAMERA_HEIGHT)
        cap.set(cv2.CAP_PROP_FPS, PredictionConfig.CAMERA_FPS)
        
        if not cap.isOpened():
            raise RuntimeError("Erro: NÃ£o foi possÃ­vel aceder Ã  webcam!")
        
        return cap
    
    def _print_initialization_summary(self):
        """Imprime resumo da inicializaÃ§Ã£o."""
        model_info = self.model_loader.get_model_info()
        
        print(f"[INIT] âœ… Sistema inicializado com sucesso!")
        print(f"[INIT] Modelo: {model_info['input_size']} â†’ {model_info['output_size']} classes")
        print(f"[INIT] Device: {model_info['device']}")
        print(f"[INIT] Accuracy treino: {model_info['best_accuracy']}")
        print(f"[INIT] SuavizaÃ§Ã£o: janela de {PredictionConfig.SMOOTHING_WINDOW} frames")
        print(f"[INIT] Limiar confianÃ§a: {PredictionConfig.CONFIDENCE_THRESHOLD}")
    
    def _update_fps(self):
        """Atualiza cÃ¡lculo de FPS."""
        if self.frame_count % PredictionConfig.FPS_UPDATE_INTERVAL == 0:
            current_time = time.time()
            if self.last_fps_update > 0:
                time_diff = current_time - self.last_fps_update
                self.current_fps = PredictionConfig.FPS_UPDATE_INTERVAL / time_diff
            self.last_fps_update = current_time
    
    def run(self):
        """Executa sistema de prediÃ§Ãµes em tempo real."""
        print(f"\n[PREDICTION] ğŸ¬ Iniciando prediÃ§Ãµes em tempo real")
        print("[PREDICTION] Pressione 'q' para sair, 's' para capturar screenshot")
        
        cv2.namedWindow('Predicoes em Tempo Real', cv2.WINDOW_NORMAL)
        cv2.resizeWindow('Predicoes em Tempo Real', PredictionConfig.CAMERA_WIDTH, PredictionConfig.CAMERA_HEIGHT)
        
        try:
            with self.mp_holistic.Holistic(
                min_detection_confidence=PredictionConfig.MIN_DETECTION_CONFIDENCE,
                min_tracking_confidence=PredictionConfig.MIN_TRACKING_CONFIDENCE,
                refine_face_landmarks=False,
                model_complexity=PredictionConfig.MODEL_COMPLEXITY
            ) as holistic:
                
                while self.cap.isOpened():
                    success, image = self.cap.read()
                    if not success:
                        continue
                    
                    self.frame_count += 1
                    self._update_fps()
                    
                    # Processar MediaPipe
                    image.flags.writeable = False
                    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    results = holistic.process(image_rgb)
                    
                    # Obter status de detecÃ§Ã£o
                    detection_status = self.preprocessor.get_detection_status(results)
                    
                    # Fazer prediÃ§Ã£o
                    prediction, confidence = self._make_prediction(results)
                    
                    # Adicionar Ã  suavizaÃ§Ã£o
                    if prediction >= 0:  # PrediÃ§Ã£o vÃ¡lida
                        self.smoother.add_prediction(prediction, confidence)
                    
                    # Obter prediÃ§Ã£o suavizada
                    smoothed_pred, smoothed_conf = self.smoother.get_smoothed_prediction()
                    stability = self.smoother.get_stability_score()
                    
                    # VisualizaÃ§Ã£o
                    image.flags.writeable = True
                    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
                    
                    # Desenhar landmarks
                    self.visualizer.draw_landmarks(image, results)
                    
                    # Adicionar overlay de prediÃ§Ã£o
                    display_pred = prediction if prediction >= 0 else -1
                    display_smoothed = smoothed_pred if smoothed_pred >= 0 else -1
                    
                    self.visualizer.add_prediction_overlay(
                        image, display_pred, confidence,
                        display_smoothed, smoothed_conf, stability,
                        self.current_fps, detection_status
                    )
                    
                    # Mostrar frame
                    cv2.imshow('Predicoes em Tempo Real', image)
                    
                    # Debug periÃ³dico
                    if self.frame_count % 60 == 0:  # A cada ~2 segundos
                        self._print_debug_info(detection_status, prediction, confidence, 
                                             smoothed_pred, smoothed_conf, stability)
                    
                    # Verificar teclas
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("[PREDICTION] ğŸ›‘ Saindo...")
                        break
                    elif key == ord('s'):
                        self._save_screenshot(image)
        
        finally:
            self._cleanup()
    
    def _make_prediction(self, results) -> Tuple[int, float]:
        """Faz prediÃ§Ã£o baseada nos landmarks detectados."""
        try:
            # Extrair features
            feature_vector = self.preprocessor.create_feature_vector(results)
            
            # Verificar se hÃ¡ landmarks suficientes
            non_zero_features = np.count_nonzero(feature_vector)
            total_features = len(feature_vector)
            detection_ratio = non_zero_features / total_features
            
            # Se muito poucas detecÃ§Ãµes, nÃ£o fazer prediÃ§Ã£o
            if detection_ratio < 0.1:  # Menos de 10% de landmarks detectados
                return -1, 0.0
            
            # Converter para tensor
            feature_tensor = torch.tensor(feature_vector, dtype=torch.float32).unsqueeze(0).to(self.device)
            
            # Fazer prediÃ§Ã£o
            predictions, confidences, probs = self.model.predict_with_confidence(feature_tensor)
            
            prediction = predictions[0].item()
            confidence = confidences[0].item()
            
            # Aplicar limiar de confianÃ§a
            if confidence < PredictionConfig.CONFIDENCE_THRESHOLD:
                return -1, confidence
            
            return prediction, confidence
            
        except Exception as e:
            print(f"[ERROR] Erro na prediÃ§Ã£o: {e}")
            return -1, 0.0
    
    def _print_debug_info(self, detection_status, prediction, confidence, 
                         smoothed_pred, smoothed_conf, stability):
        """Imprime informaÃ§Ãµes de debug."""
        detected = [k for k, v in detection_status.items() if v]
        detected_str = "+".join(detected) if detected else "NONE"
        
        print(f"[DEBUG] Frame {self.frame_count}: "
              f"Det={detected_str} | "
              f"Pred={prediction + 1 if prediction >= 0 else 'N/A'}({confidence:.2f}) | "
              f"Smooth={smoothed_pred + 1 if smoothed_pred >= 0 else 'N/A'}({smoothed_conf:.2f}) | "
              f"Stability={stability:.2f} | FPS={self.current_fps:.1f}")
    
    def _save_screenshot(self, image):
        """Salva screenshot com timestamp."""
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"prediction_screenshot_{timestamp}.png"
        cv2.imwrite(filename, image)
        print(f"[SCREENSHOT] Salvo: {filename}")
    
    def _cleanup(self):
        """Limpa recursos."""
        self.cap.release()
        cv2.destroyAllWindows()
        
        # EstatÃ­sticas finais
        total_time = time.time() - self.start_time
        avg_fps = self.frame_count / total_time if total_time > 0 else 0
        
        print(f"\n[FINAL] ğŸ“Š EstatÃ­sticas da sessÃ£o:")
        print(f"[FINAL] Frames processados: {self.frame_count}")
        print(f"[FINAL] Tempo total: {total_time:.1f}s")
        print(f"[FINAL] FPS mÃ©dio: {avg_fps:.1f}")
        print(f"[FINAL] ğŸ”š Sistema encerrado")


# ===========================================================================================
# FUNÃ‡ÃƒO PRINCIPAL
# ===========================================================================================

def main():
    """FunÃ§Ã£o principal do programa."""
    try:
        print("ğŸ¯ Sistema de PrediÃ§Ãµes em Tempo Real")
        print("=" * 60)
        
        # Caminho do modelo (ajustar conforme necessÃ¡rio)
        model_path = Path(__file__).resolve().parent / ".." / "data" / "dataset30" / "output30" / "trained_model_coordinates_only.pth"
        
        # Verificar se modelo existe
        if not model_path.exists():
            print(f"âŒ Modelo nÃ£o encontrado em: {model_path}")
            print("ğŸ’¡ Certifique-se de que o modelo foi treinado e salvo corretamente.")
            return
        
        print(f"[MAIN] Modelo encontrado: {model_path}")
        
        # Mostrar funcionalidades
        print(f"\nğŸ¯ Funcionalidades Ativas:")
        print(f"âš¡ - PrediÃ§Ãµes em tempo real")
        print(f"ğŸ¬ - Captura de pose com MediaPipe")
        print(f"ğŸ“Š - SuavizaÃ§Ã£o de prediÃ§Ãµes")
        print(f"ğŸ” - VisualizaÃ§Ã£o de confianÃ§a")
        print(f"ğŸ¯ - DetecÃ§Ã£o de estabilidade")
        
        # Inicializar sistema
        print(f"\n[MAIN] Iniciando em 3 segundos...")
        time.sleep(3)
        
        system = RealtimePredictionSystem(str(model_path))
        system.run()
        
    except KeyboardInterrupt:
        print("\n[MAIN] ğŸ›‘ Interrompido pelo utilizador")
    except Exception as e:
        print(f"\n[ERROR] âŒ Erro: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("[MAIN] ğŸ”š Programa terminado")


if __name__ == "__main__":
    main()